{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "771ca230",
   "metadata": {},
   "source": [
    "# Data Analytics with PySpark & Flask"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad4b9080",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fd97c47",
   "metadata": {},
   "source": [
    "Load data from db to Pandas df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ad165129",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/vg/zghjwz1n4szdmtsp_xskg4r40000gp/T/ipykernel_71105/3676257996.py:19: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df_int = pd.read_sql(q_int, conn)\n",
      "/var/folders/vg/zghjwz1n4szdmtsp_xskg4r40000gp/T/ipykernel_71105/3676257996.py:20: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df_stu = pd.read_sql(q_stu, conn)\n",
      "/var/folders/vg/zghjwz1n4szdmtsp_xskg4r40000gp/T/ipykernel_71105/3676257996.py:21: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df_lec = pd.read_sql(q_lec, conn)\n",
      "/var/folders/vg/zghjwz1n4szdmtsp_xskg4r40000gp/T/ipykernel_71105/3676257996.py:22: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df_q = pd.read_sql(q_q, conn)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import psycopg2\n",
    "\n",
    "# connect to PostgreSQL db\n",
    "conn = psycopg2.connect(\n",
    "    dbname=\"54_proj\",\n",
    "    user=\"postgres\",\n",
    "    password=\"123\",\n",
    "    host=\"localhost\",\n",
    "    port=\"5432\"\n",
    ")\n",
    "\n",
    "q_int = \"SELECT * FROM interactions\"\n",
    "q_stu = \"SELECT * FROM students\"\n",
    "q_lec = \"SELECT * FROM lectures\"\n",
    "q_q = \"SELECT * FROM questions\"\n",
    "\n",
    "# load sql to df\n",
    "df_int = pd.read_sql(q_int, conn)\n",
    "df_stu = pd.read_sql(q_stu, conn)\n",
    "df_lec = pd.read_sql(q_lec, conn)\n",
    "df_q = pd.read_sql(q_q, conn)\n",
    "\n",
    "dfs = [df_int, df_stu, df_lec, df_q]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "51e31dd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23000713, 7)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_int.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5601298c",
   "metadata": {},
   "source": [
    "Create PySpark dataframe from pandas df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1a6974e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/20 12:27:09 WARN Utils: Your hostname, MacBook-Pro-295.local resolves to a loopback address: 127.0.0.1; using 10.206.88.24 instead (on interface en0)\n",
      "24/04/20 12:27:10 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/04/20 12:27:11 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "24/04/20 12:27:14 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8g\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.functions\n",
    "from pyspark import SparkContext, SparkConf\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Pandas to Spark\") \\\n",
    "    .config(\"spark.driver.memory\", \"8g\") \\\n",
    "    .config(\"spark.executor.memory\", \"4g\") \\\n",
    "    .getOrCreate()\n",
    "sc = spark.sparkContext\n",
    "\n",
    "#check driver memory \n",
    "print(sc._conf.get('spark.driver.memory'))\n",
    "\n",
    "questions = spark.createDataFrame(df_q)\n",
    "students = spark.createDataFrame(df_stu)\n",
    "lectures = spark.createDataFrame(df_lec)\n",
    "interactions = spark.createDataFrame(df_int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91ae3553",
   "metadata": {},
   "source": [
    "Select columns that is relevant to our analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d6046a36",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "interactions = interactions.select('user_id','question_id', 'user_answer', 'elapsed_time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "82d8bd98",
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = questions.select('question_id', 'correct_answer', 'tags')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1d16808c",
   "metadata": {},
   "outputs": [],
   "source": [
    "lectures = lectures.select('lecture_id', 'tags', 'video_length')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d9ae75b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, split, explode, array_contains\n",
    "\n",
    "#split tags into list then explode to separate rows\n",
    "exploded_questions = questions.withColumn(\"tags_array\", explode(split(col(\"tags\"), \";\")))\n",
    "\n",
    "#left join on the tags column\n",
    "joined_df = lectures.join(exploded_questions, lectures.tags == exploded_questions.tags_array, how='left')\n",
    "\n",
    "# Select lectures that do not have any associated questions\n",
    "lectures_without_questions = joined_df.filter(col(\"question_id\").isNull())\n",
    "\n",
    "# Select distinct lectures without questions to avoid duplicate entries\n",
    "distinct_lectures_without_questions = lectures_without_questions.select(\"lecture_id\",\"video_length\").distinct()\n",
    "\n",
    "## filter letures that has no associated questions\n",
    "lectures = lectures.join(\n",
    "    distinct_lectures_without_questions,\n",
    "    on=\"lecture_id\",\n",
    "    how=\"left_anti\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "66960aa2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "279"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# free up memory after loading into spark\n",
    "import gc\n",
    "dfs = [df_int, df_stu, df_lec, df_q]\n",
    "for df in dfs:\n",
    "    del df\n",
    "del dfs\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63b92925",
   "metadata": {},
   "source": [
    "## Analyze Student Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "98b0a4a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/20 12:43:51 WARN CacheManager: Asked to cache already cached data.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[question_id: string, user_id: bigint, user_answer: string, elapsed_time: bigint, correct_answer: string, tags: string, average_time_taken_on_this_q: double, average_correctness_of_this_q: double]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql import Window\n",
    "from pyspark.sql.functions import avg, count, broadcast, when\n",
    "\n",
    "# Broadcasting 'questions' as it is much smaller than 'interactions'\n",
    "questions_df = broadcast(questions)\n",
    "correctness_df = interactions.join(questions_df, \"question_id\")\n",
    "\n",
    "# define window specification\n",
    "window_spec = Window.partitionBy(\"question_id\")\n",
    "\n",
    "# add calculated columns with window functions\n",
    "correctness_df = correctness_df.withColumn(\n",
    "    \"average_time_taken_on_this_q\",\n",
    "    #convert millisecond to second\n",
    "    (avg(\"elapsed_time\").over(window_spec) / 1000)\n",
    ").withColumn(\n",
    "    \"average_correctness_of_this_q\",\n",
    "    #use percentage\n",
    "    (avg(when(col(\"user_answer\") == col(\"correct_answer\"), 1).otherwise(0)).over(window_spec)*100)\n",
    ")\n",
    "#for better performance\n",
    "correctness_df.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9dca0e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate summary statistics for student: student id\n",
    "def analyze_student_performance(student_id):\n",
    "    # Filter for specific student interactions\n",
    "    student_specific = correctness_df.filter(col(\"user_id\") == student_id)\n",
    "\n",
    "    # calculate student's correctness and total questions completed\n",
    "    correctness_metrics = student_specific.agg(\n",
    "        avg(when(col(\"user_answer\") == col(\"correct_answer\"), 1).otherwise(0)).alias(\"student_correctness\"),\n",
    "        count(\"*\").alias(\"total_count\")\n",
    "    ).collect()[0]\n",
    "    \n",
    "    student_correctness = correctness_metrics['student_correctness'] * 100\n",
    "    total_questions_solved = correctness_metrics['total_count']\n",
    "\n",
    "    # calculate overall correctness using 'correctness_df' defined earlier\n",
    "    overall_correct = correctness_df.filter(col(\"user_answer\") == col(\"correct_answer\")).count()\n",
    "    total_count = correctness_df.count()\n",
    "    overall_correctness = overall_correct / total_count if total_count > 0 else 0\n",
    "    \n",
    "    #calculate how this student's performance compared to average\n",
    "    correctness_comparison = (student_correctness - overall_correctness * 100)\n",
    "\n",
    "    # extract wrong answers with additional details & rename columsn\n",
    "    wrong_answers_df = student_specific.filter(col(\"user_answer\") != col(\"correct_answer\")).select(\n",
    "        col(\"question_id\"),\n",
    "        col(\"elapsed_time\"),\n",
    "        col(\"average_time_taken_on_this_q\"),\n",
    "        col(\"average_correctness_of_this_q\"),\n",
    "        col(\"user_answer\").alias(\"student_answer\"),\n",
    "        col(\"correct_answer\").alias(\"correct_answer\")\n",
    "    ).withColumn(\n",
    "    \"elapsed_time\", col('elapsed_time')/1000\n",
    "    )\n",
    "\n",
    "    return {\n",
    "        \"total_questions_solved\": total_questions_solved,\n",
    "        \"student_correctness\": student_correctness,\n",
    "        \"correctness_comparison\": correctness_comparison,\n",
    "        \"wrong_answers_df\": wrong_answers_df\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "16107c76",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread \"serve-DataFrame\" java.net.SocketTimeoutException: Accept timed out\n",
      "\tat java.net.PlainSocketImpl.socketAccept(Native Method)\n",
      "\tat java.net.AbstractPlainSocketImpl.accept(AbstractPlainSocketImpl.java:535)\n",
      "\tat java.net.ServerSocket.implAccept(ServerSocket.java:545)\n",
      "\tat java.net.ServerSocket.accept(ServerSocket.java:513)\n",
      "\tat org.apache.spark.security.SocketAuthServer$$anon$1.run(SocketAuthServer.scala:65)\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Questions Solved: 7\n",
      "Student Correctness: 28.57142857142857\n",
      "Correctness Comparison: -36.74975081983639\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [20/Apr/2024 12:47:58] \"GET /student/97657 HTTP/1.1\" 200 -        \n",
      "INFO:werkzeug:127.0.0.1 - - [20/Apr/2024 12:47:58] \"GET /student/97657 HTTP/1.1\" 200 -\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+------------+----------------------------+-----------------------------+--------------+--------------+\n",
      "|question_id|elapsed_time|average_time_taken_on_this_q|average_correctness_of_this_q|student_answer|correct_answer|\n",
      "+-----------+------------+----------------------------+-----------------------------+--------------+--------------+\n",
      "|      q4775|        20.0|           27.98703384968445|             73.1612162937464|             a|             b|\n",
      "|      q6731|        24.0|          30.901054030956224|           25.705061247744755|             a|             c|\n",
      "|       q297|        23.0|          19.052934407364788|           59.196394322976595|             a|             b|\n",
      "|        q68|        25.0|          21.563899868247695|            87.43961352657004|             c|             b|\n",
      "|      q5807|        12.0|                       32.78|           45.857142857142854|             c|             d|\n",
      "+-----------+------------+----------------------------+-----------------------------+--------------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#test func output\n",
    "student_id = 440454  # Replace this with an actual student ID\n",
    "results = analyze_student_performance(student_id)\n",
    "print(\"Total Questions Solved:\", results[\"total_questions_solved\"])\n",
    "print(\"Student Correctness:\", results[\"student_correctness\"])\n",
    "print(\"Correctness Comparison:\", results[\"correctness_comparison\"])\n",
    "results[\"wrong_answers_df\"].show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73d1c37d",
   "metadata": {},
   "source": [
    "### generate flask ui for student summary dashboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "363f5f96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on http://127.0.0.1:3000\n",
      "INFO:werkzeug:\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
      " * Running on http://127.0.0.1:3000\n",
      "Press CTRL+C to quit\n",
      "INFO:werkzeug:\u001b[33mPress CTRL+C to quit\u001b[0m\n",
      "127.0.0.1 - - [20/Apr/2024 12:49:32] \"GET / HTTP/1.1\" 200 -\n",
      "INFO:werkzeug:127.0.0.1 - - [20/Apr/2024 12:49:32] \"GET / HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [20/Apr/2024 12:49:34] \"POST / HTTP/1.1\" 302 -\n",
      "INFO:werkzeug:127.0.0.1 - - [20/Apr/2024 12:49:34] \"\u001b[32mPOST / HTTP/1.1\u001b[0m\" 302 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Redirecting to dashboard with student ID: 97657\n",
      "/student/97657\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [20/Apr/2024 12:49:49] \"GET /student/97657 HTTP/1.1\" 200 -        \n",
      "INFO:werkzeug:127.0.0.1 - - [20/Apr/2024 12:49:49] \"GET /student/97657 HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [20/Apr/2024 12:51:23] \"GET / HTTP/1.1\" 200 -\n",
      "INFO:werkzeug:127.0.0.1 - - [20/Apr/2024 12:51:23] \"GET / HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "from flask import Flask, render_template, request, redirect, url_for\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "@app.route('/', methods=['GET', 'POST'])\n",
    "def index():\n",
    "    if request.method == 'POST':\n",
    "        student_id = request.form['student_id']\n",
    "        print(\"Redirecting to dashboard with student ID:\", student_id)\n",
    "        print(url_for('dashboard', student_id=student_id))\n",
    "        return redirect(url_for('dashboard', student_id=student_id))\n",
    "    return render_template('index_student.html')\n",
    "\n",
    "@app.route('/student/<int:student_id>')\n",
    "def dashboard(student_id):\n",
    "    try:\n",
    "        results = analyze_student_performance(student_id)\n",
    "        results['student_id'] = student_id\n",
    "    except Exception as e:\n",
    "        print('function error!')\n",
    "        return f\"An error occurred: {e}\", 500\n",
    "    return render_template('student.html',  results = results)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(host='127.0.0.1',port=3000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0a0fcd3",
   "metadata": {},
   "source": [
    "## Analyze Lecture Quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "92e47f17",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------------------+------------------+-------------------+\n",
      "|question_id|                tags|average_time_taken|average_correctness|\n",
      "+-----------+--------------------+------------------+-------------------+\n",
      "|      q1489|          52;181;184|               1.0|                0.0|\n",
      "|      q3613|                  74|               1.0|                0.0|\n",
      "|      q1488|          53;181;184|               1.0|                0.0|\n",
      "|      q1490|          54;181;184|               1.0|                0.0|\n",
      "|     q10626|                  74|29.372523117569873|  9.841479524438808|\n",
      "|      q7771| 155;179;177;153;177| 58.84649719276178|  9.918902058640017|\n",
      "|      q9428|                  85| 36.04166666666666|               12.5|\n",
      "|      q9539|                  94| 28.41720105620453| 13.240286684270348|\n",
      "|     q16961|                  -1|103.96135398230084| 13.274336283185844|\n",
      "|      q3140|           64;52;184|23.996076086956492| 14.130434782608722|\n",
      "|      q3170|           60;55;183|23.792497786523466| 14.363010329561867|\n",
      "|      q7606| 155;158;162;156;178| 75.38729135661276| 14.539210074413624|\n",
      "|     q11704|                 134|28.539808917197636| 15.031847133757804|\n",
      "|      q7256|146;158;166;179;1...| 67.10503536977632|  15.05894962486572|\n",
      "|     q10659|                  76|30.603527607362143| 15.414110429447872|\n",
      "|      q2067|          52;183;184| 25.83368875870234|  15.95544533288522|\n",
      "|      q8895|                  85| 22.06937394247056|  17.00507614213207|\n",
      "|      q2631|       59;179;56;183| 26.48029236977194| 17.131327953044224|\n",
      "|     q10736|                 143|31.568893129770547| 17.175572519084096|\n",
      "|      q2795|           67;58;182|24.267705882352946| 17.647058823529402|\n",
      "+-----------+--------------------+------------------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#correctness df to each question \n",
    "from pyspark.sql.functions import *\n",
    "question_correctness = correctness_df.select('question_id', 'average_time_taken_on_this_q', 'average_correctness_of_this_q', 'tags')\\\n",
    "                                     .groupBy('question_id')\\\n",
    "                                     .agg(\n",
    "                                        first(\"tags\").alias(\"tags\"),\n",
    "                                        avg(\"average_time_taken_on_this_q\").alias(\"average_time_taken\"),\n",
    "                                        avg(\"average_correctness_of_this_q\").alias(\"average_correctness\")\n",
    ").sort(['average_correctness', 'average_time_taken'], ascending=[True, False])\n",
    "question_correctness.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c532f622",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, split, explode, broadcast\n",
    "\n",
    "def analyze_lecture(lecture_id):\n",
    "\n",
    "    target_lecture = lectures.filter(col(\"lecture_id\") == lecture_id)\n",
    "\n",
    "    exploded_correctness = question_correctness.withColumn(\"tag\", explode(split(col(\"tags\"), \";\")))\n",
    "\n",
    "    #lecture is much smaller than questions so use broadcast to optimize \n",
    "    broadcasted_lecture = broadcast(target_lecture)\n",
    "\n",
    "    #join correctness df with the lecture df on tags\n",
    "    related_questions = exploded_correctness.join(\n",
    "        broadcasted_lecture,\n",
    "        exploded_correctness.tag == broadcasted_lecture.tags,  # Joining on the single tag from lecture and exploded tags from correctness\n",
    "        \"inner\"\n",
    "    ).select(\n",
    "        col(\"question_id\").alias(\"Question ID\"),\n",
    "        round(col(\"average_time_taken\"), 2).alias(\"Average Time Taken (s)\"),\n",
    "        round(col(\"average_correctness\"), 2).alias(\"Average Correctness (%)\")\n",
    "    )\n",
    "    \n",
    "    summary = related_questions.agg(\n",
    "        count(\"Question ID\").alias(\"Total Associated Questions\"),\n",
    "        round(avg(\"Average Time Taken (s)\"), 2).alias(\"Overall Average Time (s)\"),\n",
    "        round(avg(\"Average Correctness (%)\"), 2).alias(\"Overall Average Correctness (%)\")\n",
    "    )\n",
    "\n",
    "    return summary, related_questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "03c6af25",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+------------------------+-------------------------------+\n",
      "|total_questions|Overall Average Time (s)|Overall Average Correctness (%)|\n",
      "+---------------+------------------------+-------------------------------+\n",
      "|             36|                   21.38|                           82.7|\n",
      "+---------------+------------------------+-------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#example output\n",
    "summary, results = analyze_lecture('l427')\n",
    "summary.show()\n",
    "#results.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85f6b6ab",
   "metadata": {},
   "source": [
    "### generate flask ui for lecture summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bcb894db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on http://127.0.0.1:5000\n",
      "INFO:werkzeug:\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
      " * Running on http://127.0.0.1:5000\n",
      "Press CTRL+C to quit\n",
      "INFO:werkzeug:\u001b[33mPress CTRL+C to quit\u001b[0m\n",
      "127.0.0.1 - - [20/Apr/2024 12:52:34] \"GET / HTTP/1.1\" 200 -                     \n",
      "INFO:werkzeug:127.0.0.1 - - [20/Apr/2024 12:52:34] \"GET / HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [20/Apr/2024 12:52:35] \"GET /favicon.ico HTTP/1.1\" 404 -\n",
      "INFO:werkzeug:127.0.0.1 - - [20/Apr/2024 12:52:35] \"\u001b[33mGET /favicon.ico HTTP/1.1\u001b[0m\" 404 -\n",
      "127.0.0.1 - - [20/Apr/2024 12:52:46] \"POST / HTTP/1.1\" 302 -\n",
      "INFO:werkzeug:127.0.0.1 - - [20/Apr/2024 12:52:46] \"\u001b[32mPOST / HTTP/1.1\u001b[0m\" 302 -\n",
      "127.0.0.1 - - [20/Apr/2024 12:53:56] \"GET /summary/l695 HTTP/1.1\" 200 -         \n",
      "INFO:werkzeug:127.0.0.1 - - [20/Apr/2024 12:53:56] \"GET /summary/l695 HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [20/Apr/2024 13:03:05] \"GET / HTTP/1.1\" 200 -                     \n",
      "INFO:werkzeug:127.0.0.1 - - [20/Apr/2024 13:03:05] \"GET / HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "from flask import Flask, render_template, request, redirect, url_for\n",
    "import pandas as pd\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "@app.route(\"/\", methods=['GET', 'POST'])\n",
    "def index():\n",
    "    if request.method == 'POST':\n",
    "        lecture_id = request.form.get('lecture_id')\n",
    "        if lecture_id:\n",
    "            return redirect(url_for('display_summary', lecture_id=lecture_id))\n",
    "    # Assume lecture_ids are extracted properly for display\n",
    "    lecture_ids = lectures.select(\"lecture_id\").distinct().collect()\n",
    "    return render_template('index_lecture.html', lecture_ids=lecture_ids)\n",
    "\n",
    "@app.route(\"/summary/<lecture_id>\")\n",
    "def display_summary(lecture_id):\n",
    "    summary_df, detailed_df = analyze_lecture(lecture_id)\n",
    "    # Convert Spark DataFrames to Pandas for easier handling in HTML\n",
    "    detailed_html = detailed_df.toPandas().to_html(classes=\"table table-striped\", index=False)\n",
    "    summary_html = summary_df.toPandas().to_html(classes=\"table table-striped\", index=False)\n",
    "    return render_template('lecture.html', lecture_id = lecture_id, detailed_html=detailed_html, summary_html=summary_html)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(host='127.0.0.1',port=5000)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4808c19",
   "metadata": {},
   "source": [
    "Thank you :)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
